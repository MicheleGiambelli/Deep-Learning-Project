{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicheleGiambelli/Deep-Learning-Project/blob/Michele/Dataset%20preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywTK58qH9Gdx"
      },
      "outputs": [],
      "source": [
        "# Pipeline to test only one image\n",
        "# my_image = Image.open(\"/content/drive/MyDrive/Università /Project Deep Learning/food_13_small/beef_tartare/101073.jpg\")\n",
        "# pil_image = np.array(my_image)\n",
        "# grayscale_img = to_grayscale(pil_image)\n",
        "# final_img = prepare_image(grayscale_img, height=224, width=224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "mRxFhCbn9Gdn"
      },
      "outputs": [],
      "source": [
        "import os, csv\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p7pa5yL-9Gdn"
      },
      "outputs": [],
      "source": [
        "# Function for visualization\n",
        "def visualize_img(image: np.ndarray):\n",
        "    img = image.copy()\n",
        "    img = np.squeeze(img)\n",
        "    img = Image.fromarray(img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Don't run the following code\n",
        "Only preparation of dataset"
      ],
      "metadata": {
        "id": "0Vs_XvqCMk4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4Vp0Up49Gdo",
        "outputId": "bff071b5-7234-456b-b919-b3162f05dca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File c:\\Users\\miche.LAPTOP-KKEENNGV\\OneDrive\\Desktop\\Università\\2° Anno\\Advanced Programming and Deep Learning for AI\\Part 2 (Lin)\\Project\\food_13\\images\\.DS_Store is not an image.\n",
            "Image c:\\Users\\miche.LAPTOP-KKEENNGV\\OneDrive\\Desktop\\Università\\2° Anno\\Advanced Programming and Deep Learning for AI\\Part 2 (Lin)\\Project\\food_13\\images\\chicken_wings\\1009927.jpg is invalid: Dimensions are too small (140x512).\n",
            "Deleted invalid image: c:\\Users\\miche.LAPTOP-KKEENNGV\\OneDrive\\Desktop\\Università\\2° Anno\\Advanced Programming and Deep Learning for AI\\Part 2 (Lin)\\Project\\food_13\\images\\chicken_wings\\1009927.jpg\n",
            "Image c:\\Users\\miche.LAPTOP-KKEENNGV\\OneDrive\\Desktop\\Università\\2° Anno\\Advanced Programming and Deep Learning for AI\\Part 2 (Lin)\\Project\\food_13\\images\\hot_dog\\1114633.jpg is invalid: Dimensions are too small (512x193).\n",
            "Deleted invalid image: c:\\Users\\miche.LAPTOP-KKEENNGV\\OneDrive\\Desktop\\Università\\2° Anno\\Advanced Programming and Deep Learning for AI\\Part 2 (Lin)\\Project\\food_13\\images\\hot_dog\\1114633.jpg\n"
          ]
        }
      ],
      "source": [
        "def validate_images(input_dir):\n",
        "    # Get absolute path\n",
        "    input_dir = os.path.abspath(input_dir)\n",
        "\n",
        "    try:\n",
        "        # Check if the directory exists\n",
        "        os.listdir(input_dir)\n",
        "    except FileNotFoundError:\n",
        "        raise ValueError(f\"{input_dir} is not an existing directory\")\n",
        "\n",
        "    # Save the path of files\n",
        "    files = []\n",
        "    for folder, subfolder, file in os.walk(input_dir):\n",
        "        for f in file:\n",
        "            files.append(os.path.join(folder, f))\n",
        "\n",
        "    # Check the images requisite\n",
        "    for idx, file_path in enumerate(files):\n",
        "        # Check the extension\n",
        "        if file_path.lower().endswith(('.jpg', '.jpeg')):\n",
        "            try:\n",
        "                # Open the image\n",
        "                my_image = Image.open(file_path)\n",
        "\n",
        "                # Check the image dimension (min 10kB, max 250 kB)\n",
        "                if os.path.getsize(file_path) > 10240 and os.path.getsize(file_path) <= 250000:\n",
        "\n",
        "                    # Check if the image is in RGB mode\n",
        "                    if my_image.mode == \"RGB\":\n",
        "\n",
        "                        #Convert my_image in numpy array\n",
        "                        image_data = np.array(my_image)\n",
        "\n",
        "                        # Check if the image has the height and width min request (100 pixel)\n",
        "                        h, w, c = image_data.shape\n",
        "                        if h >= 224 and w >= 224:\n",
        "\n",
        "                            # Check if the variance of pixels is greater than 10 to avoid monotone images\n",
        "                            if np.var(image_data) > 10:\n",
        "                                continue  # Valid image, check the next one\n",
        "                            else:\n",
        "                                print(f\"Image {file_path} is invalid: Variance is less than 10.\")\n",
        "                        else:\n",
        "                            print(f\"Image {file_path} is invalid: Dimensions are too small ({h}x{w}).\")\n",
        "                    else:\n",
        "                        print(f\"Image {file_path} is invalid: Not in RGB mode.\")\n",
        "                else:\n",
        "                    print(f\"Image {file_path} is invalid: File size is not correct.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Image {file_path} could not be processed: {e}\")\n",
        "\n",
        "            # Delete the image is not valid\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                print(f\"Deleted invalid image: {file_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to delete {file_path}: {e}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"File {file_path} is not an image.\")\n",
        "\n",
        "\n",
        "validate_images(\"food_13/images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxgFw4Zc9Gdp"
      },
      "source": [
        "Now we are going to reduce the number of images in each folder. The 13th folders have 1000 images each one of them. We are going to reduce them of the 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HETElMON9Gdp",
        "outputId": "67dd158d-2187-43f9-c488-142e00c4e6bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder 'food_13/images\\beef_tartare' reduced to 200 images.\n",
            "Folder 'food_13/images\\bruschetta' reduced to 200 images.\n",
            "Folder 'food_13/images\\caesar_salad' reduced to 200 images.\n",
            "Folder 'food_13/images\\cannoli' reduced to 200 images.\n",
            "Folder 'food_13/images\\chicken_wings' reduced to 200 images.\n",
            "Folder 'food_13/images\\chocolate_cake' reduced to 200 images.\n",
            "Folder 'food_13/images\\club_sandwich' reduced to 200 images.\n",
            "Folder 'food_13/images\\dumplings' reduced to 200 images.\n",
            "Folder 'food_13/images\\hot_dog' reduced to 200 images.\n",
            "Folder 'food_13/images\\ice_cream' reduced to 200 images.\n",
            "Folder 'food_13/images\\pizza' reduced to 200 images.\n",
            "Folder 'food_13/images\\ramen' reduced to 200 images.\n"
          ]
        }
      ],
      "source": [
        "def reduce_images(input_dir, output_dir, num_images):\n",
        "    # List all the files in the selected folder\n",
        "    all_files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n",
        "\n",
        "    # Random selection of the files that will be mantained\n",
        "    files_to_mantain = random.sample(all_files, num_images)\n",
        "\n",
        "    # Check that the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # CCopy selected files in the output directory\n",
        "    for file in files_to_mantain:\n",
        "        shutil.copy(os.path.join(input_dir, file), os.path.join(output_dir, file))\n",
        "\n",
        "    print(f\"Folder '{input_dir}' reduced to {num_images} images.\")\n",
        "\n",
        "\n",
        "\n",
        "input_dir = \"food_13/images\"\n",
        "output_dir = \"food_13_small\"\n",
        "# Percentage of images to mantain\n",
        "num_images = 200\n",
        "# Set the seed\n",
        "random.seed(42)\n",
        "\n",
        "# Apply the function to all the folders\n",
        "for folder in os.listdir(input_dir):\n",
        "    folder_dir = os.path.join(input_dir, folder)\n",
        "    output_folder_dir = os.path.join(output_dir, folder)\n",
        "    if os.path.isdir(folder_dir):\n",
        "        reduce_images(folder_dir, output_folder_dir, num_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96P_gCYj9Gdq"
      },
      "source": [
        "Now we create a csv file for the lables. Each images in the dataset will have its label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoujOA729Gds"
      },
      "outputs": [],
      "source": [
        "# Create csv file\n",
        "\n",
        "input_dir = \"food_13_small\"\n",
        "csv_file_path = \"labels.csv\"\n",
        "\n",
        "with open(csv_file_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
        "    writer = csv.writer(csv_file, delimiter=';')\n",
        "    # Head\n",
        "    writer.writerow([\"id\", \"name\", \"label\"])\n",
        "    # Itera attraverso ogni cartella\n",
        "    idx = 0\n",
        "    for folder in os.listdir(input_dir):\n",
        "        folder_path = os.path.join(input_dir, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            # Itera attraverso i file nella cartella\n",
        "            for file in os.listdir(folder_path):\n",
        "                if os.path.isfile(os.path.join(folder_path, file)):\n",
        "                    # Scrivi nome del file e label (nome della cartella)\n",
        "                    writer.writerow([idx, file, folder])\n",
        "                    idx += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start from here\n",
        "## Preprocessing of the images"
      ],
      "metadata": {
        "id": "ceEvd5LlMtwI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uva_B6Jn9Gdt"
      },
      "source": [
        "### Converts images to grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_ACraL5M9Gdu"
      },
      "outputs": [],
      "source": [
        "def to_grayscale(pil_image: np.ndarray):\n",
        "    if pil_image.ndim == 2: #.ndim check the dimension of the pil array\n",
        "        return pil_image.copy()[None] #Image already B&W\n",
        "    \"\"\"\n",
        "    None --> Aggiunge una nuova dimensione al primo asse. (H, W) --> (1, H, W)\n",
        "    Nei framework come PyTorch, i modelli spesso richiedono input con una dimensione di batch,\n",
        "    anche se hai solo una singola immagine. [None] aggiunge questa dimensione di batch.\n",
        "    Same is pil_image.copy()[np.newaxis, :, :]. Qui viene esplicitato l'utilizzo di np.newaxis e si specificano\n",
        "    tre dimensioni: una nuova dimensione (aggiunta come primo asse) seguita dagli assi originali (:, :).\n",
        "    Questo è utile se sai esattamente quante dimensioni ha il tuo array.\n",
        "    \"\"\"\n",
        "    if pil_image.ndim != 3:\n",
        "        raise ValueError(\"image must have either shape (H, W) or (H, W, 3)\")\n",
        "    if pil_image.shape[2] == 3:\n",
        "        image_copy = pil_image.copy()\n",
        "    else:\n",
        "        raise ValueError(f\"image has shape (H, W, {pil_image.shape[2]}), but it should have (H, W, 3)\")\n",
        "\n",
        "    # Normalize the image to [0, 1] range\n",
        "    rgb = image_copy / 255\n",
        "\n",
        "    # Colorimetric conversion to grayscale\n",
        "    C_linear = np.where(\n",
        "        rgb < 0.04045,\n",
        "        rgb / 12.92,\n",
        "        ((rgb + 0.055) / 1.055) ** 2.4\n",
        "    )\n",
        "\n",
        "    Y_linear = 0.2126 * C_linear[:,:, 0] + 0.7152 * C_linear[:,:, 1] + 0.0722 * C_linear[:,:,2]\n",
        "\n",
        "    Y = np.where(\n",
        "        Y_linear < 0.0031308,\n",
        "        12.92 * Y_linear,\n",
        "        1.055 * Y_linear ** (1 / 2.4) - 0.055\n",
        "    )\n",
        "    grayscale = Y * 255\n",
        "\n",
        "    # Mantain coherence between values in grayscale image and values original pil_image\n",
        "    if np.issubdtype(pil_image.dtype, np.integer):\n",
        "        grayscale = np.round(grayscale)\n",
        "\n",
        "    # Converts the grayscale array to the data type (dtype) of the original pil_image\n",
        "    grayscale = grayscale.astype(pil_image.dtype)\n",
        "\n",
        "    # Add tnew dimension, as at the beginning with [None]\n",
        "    grayscale = np.expand_dims(grayscale, axis=0)\n",
        "\n",
        "    return grayscale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8B8LD7T9Gdv"
      },
      "source": [
        "### Resize the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5pHkoEC_9Gdw"
      },
      "outputs": [],
      "source": [
        "def prepare_image(image: np.ndarray, height: int, width: int):\n",
        "\n",
        "    image = image.copy()\n",
        "\n",
        "    # Cropping Height\n",
        "    if image.shape[1] > height:\n",
        "        crop_size = image.shape[1] - height\n",
        "        crop_top = crop_size // 2\n",
        "        crop_bottom = crop_size - crop_top\n",
        "        image = image[:, crop_bottom:-crop_top, :]\n",
        "    # Padding Height\n",
        "    else:\n",
        "        padding_size = height - image.shape[1]      # Number of pixels to add\n",
        "        top_pad = padding_size // 2                 # How many pad pixels on top\n",
        "        bottom_pad = padding_size - top_pad         # How many pad pixels on bottom\n",
        "        image = np.pad(image, ((0, 0), (top_pad, bottom_pad), (0, 0)), mode='edge')\n",
        "\n",
        "    # Cropping Width\n",
        "    if image.shape[2] > width:\n",
        "        crop_size = image.shape[2] - width\n",
        "        left_crop = crop_size // 2\n",
        "        right_crop = crop_size - left_crop\n",
        "        image = image[:, :, left_crop:-right_crop]\n",
        "    # Padding Width\n",
        "    else:\n",
        "        padding_size = width - image.shape[2]\n",
        "        left_pad = padding_size // 2\n",
        "        right_pad = padding_size - left_pad\n",
        "        image = np.pad(image, ((0, 0), (0, 0), (left_pad, right_pad)), mode='edge')\n",
        "        \"\"\"\n",
        "        ((0, 0), (top_pad, bottom_pad), (0, 0)): Questo è l'argomento pad_width, che specifica quanto\n",
        "        padding deve essere aggiunto a ciascun lato dell'array lungo ciascuna delle sue dimensioni.\n",
        "        Qui, stiamo specificando il padding solo per l'asse verticale (dimensione dell'immagine),\n",
        "        quindi (0, 0) significa che non viene aggiunto padding all'array lungo la prima e la terza\n",
        "        dimensione (l'asse dei canali dei colori per un'immagine a colori e la larghezza).\n",
        "        mode='edge': Questo specifica la modalità di padding, che in questo caso è 'edge'.\n",
        "        La modalità 'edge' significa che il valore del bordo dell'immagine verrà utilizzato\n",
        "        per estendere il padding. In altre parole, i pixel lungo i bordi dell'immagine vengono replicati\n",
        "        per riempire lo spazio di padding\n",
        "\n",
        "        https://numpy.org/doc/stable/reference/generated/numpy.pad.html\n",
        "        \"\"\"\n",
        "\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the dataset"
      ],
      "metadata": {
        "id": "keDCfltuM-ek"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "MuqM38jn9Gdy"
      },
      "outputs": [],
      "source": [
        "class ImagesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset_dir, width = 224, height = 224, dtype = None):\n",
        "        \"\"\"\n",
        "        image_dir: direcotry of the images\n",
        "        dtype:\n",
        "        \"\"\"\n",
        "        if width < 224 or height < 224:\n",
        "            raise ValueError(\"Width and height must be at least 224.\")\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "\n",
        "        # Get absolute paths of image files and sort them\n",
        "        # Get absolute paths of image files and sort them\n",
        "        abs_path = os.path.join(image_dir) #Take absolute path\n",
        "        all_files = os.listdir(abs_path) #List of files in abs path\n",
        "\n",
        "        files = []\n",
        "        class2id = {}\n",
        "\n",
        "        for f in all_files:\n",
        "            if f.split('.')[-1] == \"jpg\":\n",
        "                files.append(os.path.join(abs_path, f))\n",
        "\n",
        "            if f.split('.')[-1] == \"csv\":\n",
        "                # Load class names from CSV file and assign class IDs\n",
        "                self.df = pd.read_csv(os.path.join(abs_path, f), sep=';', header=0)\n",
        "                # Take one time all the classes in label column, and convert them to a list\n",
        "                classes = self.df[\"label\"].unique().tolist()\n",
        "                classes = sorted(classes)\n",
        "                for idx, class_i in enumerate(classes):\n",
        "                    class2id[class_i] = idx\n",
        "                self.df['classes_idx'] = self.df['label'].map(class2id)\n",
        "\n",
        "        self.image_filepaths = files\n",
        "        self.dtype = dtype\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load i-th image\n",
        "        image = Image.open(self.image_filepaths[index])\n",
        "\n",
        "        # Convert the image in an numpy array with specified dtype if dtype is not None\n",
        "        image = np.array(image, dtype=self.dtype)\n",
        "\n",
        "        # Convert the image to grayscale\n",
        "        image = to_grayscale(image)\n",
        "\n",
        "        # Used the prepare_image function to rescale the image to the width and height specified in the __init__\n",
        "        image = prepare_image(image, self.width, self.height)\n",
        "\n",
        "        # Convert to tensor and normalize the pixels\n",
        "        image = torch.tensor(image, dtype=torch.float32)/255.0\n",
        "\n",
        "        file_name = os.path.basename(self.image_filepaths[index])\n",
        "        class_id = self.df['classes_idx'][self.df['name'] == file_name].values[0]\n",
        "        class_name = self.df['label'][self.df['name'] == file_name].values[0]\n",
        "\n",
        "        return image, class_name, class_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "1qYoKmbv9Gdy"
      },
      "outputs": [],
      "source": [
        "image_dir = \"/content/drive/MyDrive/Università /Project Deep Learning/food_13_small\"\n",
        "dataset = ImagesDataset(image_dir, 224, 224, int)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}